{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Version2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b0f02aa4a8a14da6b0dc5b328c20684e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5971475963a8401db2ce1a79ee9e7785",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8b18b54c95b64664aee4283ade753cfd",
              "IPY_MODEL_9af7026eb73648018fe7b9d1b539cc04"
            ]
          }
        },
        "5971475963a8401db2ce1a79ee9e7785": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8b18b54c95b64664aee4283ade753cfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e13350cba21147f488711461a6dabf70",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_da07da8bf484437e960fbe044391fa02"
          }
        },
        "9af7026eb73648018fe7b9d1b539cc04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_240ba7e7957342909fe0661186c020a2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9920512/? [00:00&lt;00:00, 14801170.72it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_551a0f913da545d0b42ed3d28d378869"
          }
        },
        "e13350cba21147f488711461a6dabf70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "da07da8bf484437e960fbe044391fa02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "240ba7e7957342909fe0661186c020a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "551a0f913da545d0b42ed3d28d378869": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7f6311ff54a647fcbc1287e948b907df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_15bc78a97f484678a87eb720d3839d55",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d3cde0892d704bb18029d2c4cfb46f1d",
              "IPY_MODEL_58fd53aeee494b828a7f638425db4598"
            ]
          }
        },
        "15bc78a97f484678a87eb720d3839d55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d3cde0892d704bb18029d2c4cfb46f1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0402bbf36057467d8a97f197e5b767ef",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3c3927ebed3448b3b7b45618f2a3d65f"
          }
        },
        "58fd53aeee494b828a7f638425db4598": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5e12e1f2354d4ab382704399bb3794d4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 32768/? [00:00&lt;00:00, 340993.90it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e6d9870efd774af98ab4ef8f68cb02f6"
          }
        },
        "0402bbf36057467d8a97f197e5b767ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3c3927ebed3448b3b7b45618f2a3d65f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5e12e1f2354d4ab382704399bb3794d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e6d9870efd774af98ab4ef8f68cb02f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9660f3bcccbe4b85854c513f8f4b76ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e692ab4dbe364282a69596f202b79dc4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_21d189307be64773a43fecaeb4d049bc",
              "IPY_MODEL_bf0fbc24664948b49e9e7e2e205f8ce3"
            ]
          }
        },
        "e692ab4dbe364282a69596f202b79dc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "21d189307be64773a43fecaeb4d049bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1f5784c58aaf43cfabd8f11fa85dc831",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5d1198a642224c1a8e6565193490a215"
          }
        },
        "bf0fbc24664948b49e9e7e2e205f8ce3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b76723815e394c5ab1bb57cdee1ac02f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1654784/? [00:11&lt;00:00, 144015.87it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_af2808b60fc44e4da86c1ced45d4b77d"
          }
        },
        "1f5784c58aaf43cfabd8f11fa85dc831": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5d1198a642224c1a8e6565193490a215": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b76723815e394c5ab1bb57cdee1ac02f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "af2808b60fc44e4da86c1ced45d4b77d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9d7f549b1fb147dfa8b2268ed6f7f936": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4fea4144fd0949dbb506fd25b191194c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_63e07891f0174ebd9b87905af10aeb34",
              "IPY_MODEL_1716fda62c3b41efafb52169a0c1f2bd"
            ]
          }
        },
        "4fea4144fd0949dbb506fd25b191194c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "63e07891f0174ebd9b87905af10aeb34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2dcbe31fecf44577b3dd06b5f8081d30",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9c7be44704454ddc91956b76953135e7"
          }
        },
        "1716fda62c3b41efafb52169a0c1f2bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a1b1169e01c346d0bcf914359fb230a2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/? [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_28d892ad8def4dbc8e6206b400d33fa9"
          }
        },
        "2dcbe31fecf44577b3dd06b5f8081d30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9c7be44704454ddc91956b76953135e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a1b1169e01c346d0bcf914359fb230a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "28d892ad8def4dbc8e6206b400d33fa9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "khRR9VeDvPoD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cc4e72b-06de-4f45-bde6-6f5f6c6d7ee7"
      },
      "source": [
        "# prerequisites\n",
        "\n",
        "#VAE\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "bs = 100\n",
        "# MNIST Dataset\n",
        "train_dataset = datasets.MNIST(root='./mnist_data/', train=True, transform=transforms.ToTensor(), download=True)\n",
        "test_dataset = datasets.MNIST(root='./mnist_data/', train=False, transform=transforms.ToTensor(), download=False)\n",
        "\n",
        "# Data Loader (Input Pipeline)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=bs, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=bs, shuffle=False)\n",
        "\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, x_dim, h_dim2, z_dim):\n",
        "        super(VAE, self).__init__()\n",
        "        \n",
        "        # encoder part\n",
        "        # self.fc1 = nn.Linear(x_dim, h_dim1)\n",
        "        self.fc2 = nn.Linear(x_dim, h_dim2)\n",
        "        self.fc31 = nn.Linear(h_dim2, z_dim)\n",
        "        self.fc32 = nn.Linear(h_dim2, z_dim)\n",
        "        # decoder part\n",
        "        self.fc4 = nn.Linear(z_dim, h_dim2)\n",
        "        self.fc5 = nn.Linear(h_dim2, x_dim)\n",
        "        # self.fc6 = nn.Linear(h_dim1, x_dim)\n",
        "        \n",
        "    def encoder(self, x):\n",
        "        # h = F.relu(self.fc1(x))\n",
        "        h = F.relu(self.fc2(x))\n",
        "        return self.fc31(h), self.fc32(h) # mu, log_var\n",
        "    \n",
        "    def sampling(self, mu, log_var):\n",
        "        std = torch.exp(0.5*log_var)\n",
        "        eps = torch.randn_like(std)\n",
        "        return eps.mul(std).add_(mu) # return z sample\n",
        "        \n",
        "    def decoder(self, z):\n",
        "        h = F.relu(self.fc4(z))\n",
        "        # h = F.relu(self.fc5(h))\n",
        "        return F.sigmoid(self.fc5(h)) \n",
        "    \n",
        "    def forward(self, x):\n",
        "        mu, log_var = self.encoder(x.view(-1, 784))\n",
        "        z = self.sampling(mu, log_var)\n",
        "        return self.decoder(z), mu, log_var\n",
        "\n",
        "# build model\n",
        "vae = VAE(x_dim=784, h_dim2=256, z_dim=2)\n",
        "if torch.cuda.is_available():\n",
        "    vae.cuda()\n",
        "\n",
        "vae\n",
        "\n",
        "optimizer = optim.Adam(vae.parameters())\n",
        "# return reconstruction error + KL divergence losses\n",
        "def loss_function(recon_x, x, mu, log_var):\n",
        "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n",
        "    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
        "    return BCE + KLD\n",
        "\n",
        "def train(epoch):\n",
        "    vae.train()\n",
        "    train_loss = 0\n",
        "    for batch_idx, (data, _) in enumerate(train_loader):\n",
        "        data = data.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        recon_batch, mu, log_var = vae(data)\n",
        "        loss = loss_function(recon_batch, data, mu, log_var)\n",
        "        \n",
        "        loss.backward()\n",
        "        train_loss += loss.item()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if batch_idx % 100 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item() / len(data)))\n",
        "    print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss / len(train_loader.dataset)))\n",
        "def test():\n",
        "    vae.eval()\n",
        "    test_loss= 0\n",
        "    with torch.no_grad():\n",
        "        for data, _ in test_loader:\n",
        "            data = data.cuda()\n",
        "            recon, mu, log_var = vae(data)\n",
        "            \n",
        "            # sum up batch loss\n",
        "            test_loss += loss_function(recon, data, mu, log_var).item()\n",
        "        \n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('====> Test set loss: {:.4f}'.format(test_loss))\n",
        "    return test_loss\n",
        "    \n",
        "test_Loss_Contain = []\n",
        "for epoch in range(1, 51):\n",
        "    train(epoch)\n",
        "    x = test()\n",
        "    test_Loss_Contain.append(x)\n",
        "\n",
        "with torch.no_grad():\n",
        "    z = torch.randn(64, 2).cuda()\n",
        "    sample = vae.decoder(z).cuda()\n",
        "    \n",
        "    save_image(sample.view(64, 1, 28, 28), './sample_' + '.png')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1639: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 550.546289\n",
            "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 198.188105\n",
            "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 185.730605\n",
            "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 185.665566\n",
            "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 177.921211\n",
            "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 175.285273\n",
            "====> Epoch: 1 Average loss: 190.9016\n",
            "====> Test set loss: 171.6279\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 173.370488\n",
            "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 161.220342\n",
            "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 175.120957\n",
            "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 170.619785\n",
            "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 155.610869\n",
            "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 178.790566\n",
            "====> Epoch: 2 Average loss: 168.3326\n",
            "====> Test set loss: 165.1333\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 164.722832\n",
            "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 160.093809\n",
            "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 165.879297\n",
            "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 166.217031\n",
            "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 161.810479\n",
            "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 162.392803\n",
            "====> Epoch: 3 Average loss: 163.8571\n",
            "====> Test set loss: 162.1890\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 163.930313\n",
            "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 154.866758\n",
            "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 162.324570\n",
            "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 162.232451\n",
            "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 157.556826\n",
            "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 159.480576\n",
            "====> Epoch: 4 Average loss: 161.5204\n",
            "====> Test set loss: 160.1286\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 154.587197\n",
            "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 159.008174\n",
            "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 152.769512\n",
            "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 165.321348\n",
            "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 163.874199\n",
            "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 163.787861\n",
            "====> Epoch: 5 Average loss: 159.8778\n",
            "====> Test set loss: 159.1010\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 160.787480\n",
            "Train Epoch: 6 [10000/60000 (17%)]\tLoss: 165.448945\n",
            "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 159.107891\n",
            "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 160.934521\n",
            "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 147.009316\n",
            "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 145.158184\n",
            "====> Epoch: 6 Average loss: 158.6471\n",
            "====> Test set loss: 157.8797\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 152.627520\n",
            "Train Epoch: 7 [10000/60000 (17%)]\tLoss: 157.084053\n",
            "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 168.871914\n",
            "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 158.150762\n",
            "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 161.378418\n",
            "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 159.258750\n",
            "====> Epoch: 7 Average loss: 157.6930\n",
            "====> Test set loss: 157.1262\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 151.871348\n",
            "Train Epoch: 8 [10000/60000 (17%)]\tLoss: 161.332715\n",
            "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 161.958076\n",
            "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 146.844414\n",
            "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 162.319453\n",
            "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 149.049434\n",
            "====> Epoch: 8 Average loss: 156.8532\n",
            "====> Test set loss: 156.9009\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 155.239580\n",
            "Train Epoch: 9 [10000/60000 (17%)]\tLoss: 148.810762\n",
            "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 152.700459\n",
            "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 154.053535\n",
            "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 161.105947\n",
            "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 151.131514\n",
            "====> Epoch: 9 Average loss: 156.0526\n",
            "====> Test set loss: 155.8278\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 148.443887\n",
            "Train Epoch: 10 [10000/60000 (17%)]\tLoss: 158.173633\n",
            "Train Epoch: 10 [20000/60000 (33%)]\tLoss: 154.407686\n",
            "Train Epoch: 10 [30000/60000 (50%)]\tLoss: 153.892041\n",
            "Train Epoch: 10 [40000/60000 (67%)]\tLoss: 159.120615\n",
            "Train Epoch: 10 [50000/60000 (83%)]\tLoss: 158.762236\n",
            "====> Epoch: 10 Average loss: 155.3722\n",
            "====> Test set loss: 155.2119\n",
            "Train Epoch: 11 [0/60000 (0%)]\tLoss: 160.380322\n",
            "Train Epoch: 11 [10000/60000 (17%)]\tLoss: 151.479951\n",
            "Train Epoch: 11 [20000/60000 (33%)]\tLoss: 155.165342\n",
            "Train Epoch: 11 [30000/60000 (50%)]\tLoss: 159.964961\n",
            "Train Epoch: 11 [40000/60000 (67%)]\tLoss: 151.546797\n",
            "Train Epoch: 11 [50000/60000 (83%)]\tLoss: 160.636719\n",
            "====> Epoch: 11 Average loss: 154.7633\n",
            "====> Test set loss: 154.5472\n",
            "Train Epoch: 12 [0/60000 (0%)]\tLoss: 160.171055\n",
            "Train Epoch: 12 [10000/60000 (17%)]\tLoss: 152.068496\n",
            "Train Epoch: 12 [20000/60000 (33%)]\tLoss: 164.574805\n",
            "Train Epoch: 12 [30000/60000 (50%)]\tLoss: 150.689141\n",
            "Train Epoch: 12 [40000/60000 (67%)]\tLoss: 155.431504\n",
            "Train Epoch: 12 [50000/60000 (83%)]\tLoss: 152.996816\n",
            "====> Epoch: 12 Average loss: 154.2119\n",
            "====> Test set loss: 154.1969\n",
            "Train Epoch: 13 [0/60000 (0%)]\tLoss: 139.429277\n",
            "Train Epoch: 13 [10000/60000 (17%)]\tLoss: 148.473008\n",
            "Train Epoch: 13 [20000/60000 (33%)]\tLoss: 157.493203\n",
            "Train Epoch: 13 [30000/60000 (50%)]\tLoss: 151.538945\n",
            "Train Epoch: 13 [40000/60000 (67%)]\tLoss: 142.177295\n",
            "Train Epoch: 13 [50000/60000 (83%)]\tLoss: 153.932598\n",
            "====> Epoch: 13 Average loss: 153.7694\n",
            "====> Test set loss: 154.0639\n",
            "Train Epoch: 14 [0/60000 (0%)]\tLoss: 153.329023\n",
            "Train Epoch: 14 [10000/60000 (17%)]\tLoss: 148.341816\n",
            "Train Epoch: 14 [20000/60000 (33%)]\tLoss: 149.945576\n",
            "Train Epoch: 14 [30000/60000 (50%)]\tLoss: 154.355869\n",
            "Train Epoch: 14 [40000/60000 (67%)]\tLoss: 148.194922\n",
            "Train Epoch: 14 [50000/60000 (83%)]\tLoss: 152.171074\n",
            "====> Epoch: 14 Average loss: 153.2951\n",
            "====> Test set loss: 153.6149\n",
            "Train Epoch: 15 [0/60000 (0%)]\tLoss: 147.868867\n",
            "Train Epoch: 15 [10000/60000 (17%)]\tLoss: 153.358555\n",
            "Train Epoch: 15 [20000/60000 (33%)]\tLoss: 148.078242\n",
            "Train Epoch: 15 [30000/60000 (50%)]\tLoss: 163.745664\n",
            "Train Epoch: 15 [40000/60000 (67%)]\tLoss: 154.326855\n",
            "Train Epoch: 15 [50000/60000 (83%)]\tLoss: 156.268086\n",
            "====> Epoch: 15 Average loss: 152.8579\n",
            "====> Test set loss: 153.2361\n",
            "Train Epoch: 16 [0/60000 (0%)]\tLoss: 155.777930\n",
            "Train Epoch: 16 [10000/60000 (17%)]\tLoss: 152.881455\n",
            "Train Epoch: 16 [20000/60000 (33%)]\tLoss: 152.975527\n",
            "Train Epoch: 16 [30000/60000 (50%)]\tLoss: 161.606221\n",
            "Train Epoch: 16 [40000/60000 (67%)]\tLoss: 154.057471\n",
            "Train Epoch: 16 [50000/60000 (83%)]\tLoss: 152.188545\n",
            "====> Epoch: 16 Average loss: 152.5131\n",
            "====> Test set loss: 152.9615\n",
            "Train Epoch: 17 [0/60000 (0%)]\tLoss: 142.822852\n",
            "Train Epoch: 17 [10000/60000 (17%)]\tLoss: 147.920088\n",
            "Train Epoch: 17 [20000/60000 (33%)]\tLoss: 148.306729\n",
            "Train Epoch: 17 [30000/60000 (50%)]\tLoss: 155.761641\n",
            "Train Epoch: 17 [40000/60000 (67%)]\tLoss: 156.326904\n",
            "Train Epoch: 17 [50000/60000 (83%)]\tLoss: 142.080176\n",
            "====> Epoch: 17 Average loss: 152.1491\n",
            "====> Test set loss: 152.7155\n",
            "Train Epoch: 18 [0/60000 (0%)]\tLoss: 146.357598\n",
            "Train Epoch: 18 [10000/60000 (17%)]\tLoss: 163.157695\n",
            "Train Epoch: 18 [20000/60000 (33%)]\tLoss: 156.003984\n",
            "Train Epoch: 18 [30000/60000 (50%)]\tLoss: 156.463018\n",
            "Train Epoch: 18 [40000/60000 (67%)]\tLoss: 153.777959\n",
            "Train Epoch: 18 [50000/60000 (83%)]\tLoss: 147.385029\n",
            "====> Epoch: 18 Average loss: 151.8168\n",
            "====> Test set loss: 152.6950\n",
            "Train Epoch: 19 [0/60000 (0%)]\tLoss: 144.796689\n",
            "Train Epoch: 19 [10000/60000 (17%)]\tLoss: 159.504219\n",
            "Train Epoch: 19 [20000/60000 (33%)]\tLoss: 156.314141\n",
            "Train Epoch: 19 [30000/60000 (50%)]\tLoss: 157.577402\n",
            "Train Epoch: 19 [40000/60000 (67%)]\tLoss: 148.192402\n",
            "Train Epoch: 19 [50000/60000 (83%)]\tLoss: 141.231924\n",
            "====> Epoch: 19 Average loss: 151.5173\n",
            "====> Test set loss: 152.5738\n",
            "Train Epoch: 20 [0/60000 (0%)]\tLoss: 148.680176\n",
            "Train Epoch: 20 [10000/60000 (17%)]\tLoss: 158.550410\n",
            "Train Epoch: 20 [20000/60000 (33%)]\tLoss: 155.224141\n",
            "Train Epoch: 20 [30000/60000 (50%)]\tLoss: 143.113789\n",
            "Train Epoch: 20 [40000/60000 (67%)]\tLoss: 147.717012\n",
            "Train Epoch: 20 [50000/60000 (83%)]\tLoss: 140.795596\n",
            "====> Epoch: 20 Average loss: 151.2486\n",
            "====> Test set loss: 152.0571\n",
            "Train Epoch: 21 [0/60000 (0%)]\tLoss: 151.699287\n",
            "Train Epoch: 21 [10000/60000 (17%)]\tLoss: 143.436875\n",
            "Train Epoch: 21 [20000/60000 (33%)]\tLoss: 144.791533\n",
            "Train Epoch: 21 [30000/60000 (50%)]\tLoss: 145.241611\n",
            "Train Epoch: 21 [40000/60000 (67%)]\tLoss: 153.546289\n",
            "Train Epoch: 21 [50000/60000 (83%)]\tLoss: 143.055156\n",
            "====> Epoch: 21 Average loss: 150.9640\n",
            "====> Test set loss: 151.9415\n",
            "Train Epoch: 22 [0/60000 (0%)]\tLoss: 148.623760\n",
            "Train Epoch: 22 [10000/60000 (17%)]\tLoss: 146.255908\n",
            "Train Epoch: 22 [20000/60000 (33%)]\tLoss: 150.257969\n",
            "Train Epoch: 22 [30000/60000 (50%)]\tLoss: 149.480498\n",
            "Train Epoch: 22 [40000/60000 (67%)]\tLoss: 146.561602\n",
            "Train Epoch: 22 [50000/60000 (83%)]\tLoss: 150.352725\n",
            "====> Epoch: 22 Average loss: 150.7484\n",
            "====> Test set loss: 151.9720\n",
            "Train Epoch: 23 [0/60000 (0%)]\tLoss: 151.224004\n",
            "Train Epoch: 23 [10000/60000 (17%)]\tLoss: 154.049258\n",
            "Train Epoch: 23 [20000/60000 (33%)]\tLoss: 154.127715\n",
            "Train Epoch: 23 [30000/60000 (50%)]\tLoss: 148.570742\n",
            "Train Epoch: 23 [40000/60000 (67%)]\tLoss: 151.478428\n",
            "Train Epoch: 23 [50000/60000 (83%)]\tLoss: 153.940576\n",
            "====> Epoch: 23 Average loss: 150.4986\n",
            "====> Test set loss: 151.7451\n",
            "Train Epoch: 24 [0/60000 (0%)]\tLoss: 157.457451\n",
            "Train Epoch: 24 [10000/60000 (17%)]\tLoss: 153.493828\n",
            "Train Epoch: 24 [20000/60000 (33%)]\tLoss: 145.761338\n",
            "Train Epoch: 24 [30000/60000 (50%)]\tLoss: 155.465752\n",
            "Train Epoch: 24 [40000/60000 (67%)]\tLoss: 149.213809\n",
            "Train Epoch: 24 [50000/60000 (83%)]\tLoss: 141.448145\n",
            "====> Epoch: 24 Average loss: 150.3271\n",
            "====> Test set loss: 151.7476\n",
            "Train Epoch: 25 [0/60000 (0%)]\tLoss: 145.218379\n",
            "Train Epoch: 25 [10000/60000 (17%)]\tLoss: 147.112139\n",
            "Train Epoch: 25 [20000/60000 (33%)]\tLoss: 145.613887\n",
            "Train Epoch: 25 [30000/60000 (50%)]\tLoss: 150.716777\n",
            "Train Epoch: 25 [40000/60000 (67%)]\tLoss: 156.854531\n",
            "Train Epoch: 25 [50000/60000 (83%)]\tLoss: 147.789043\n",
            "====> Epoch: 25 Average loss: 150.0461\n",
            "====> Test set loss: 151.4461\n",
            "Train Epoch: 26 [0/60000 (0%)]\tLoss: 150.996445\n",
            "Train Epoch: 26 [10000/60000 (17%)]\tLoss: 149.657656\n",
            "Train Epoch: 26 [20000/60000 (33%)]\tLoss: 145.267178\n",
            "Train Epoch: 26 [30000/60000 (50%)]\tLoss: 149.158340\n",
            "Train Epoch: 26 [40000/60000 (67%)]\tLoss: 147.456924\n",
            "Train Epoch: 26 [50000/60000 (83%)]\tLoss: 153.760215\n",
            "====> Epoch: 26 Average loss: 149.8992\n",
            "====> Test set loss: 151.2141\n",
            "Train Epoch: 27 [0/60000 (0%)]\tLoss: 148.891797\n",
            "Train Epoch: 27 [10000/60000 (17%)]\tLoss: 153.171807\n",
            "Train Epoch: 27 [20000/60000 (33%)]\tLoss: 152.961338\n",
            "Train Epoch: 27 [30000/60000 (50%)]\tLoss: 149.460322\n",
            "Train Epoch: 27 [40000/60000 (67%)]\tLoss: 152.988125\n",
            "Train Epoch: 27 [50000/60000 (83%)]\tLoss: 151.751875\n",
            "====> Epoch: 27 Average loss: 149.7314\n",
            "====> Test set loss: 151.0353\n",
            "Train Epoch: 28 [0/60000 (0%)]\tLoss: 143.940859\n",
            "Train Epoch: 28 [10000/60000 (17%)]\tLoss: 145.148633\n",
            "Train Epoch: 28 [20000/60000 (33%)]\tLoss: 143.191563\n",
            "Train Epoch: 28 [30000/60000 (50%)]\tLoss: 151.975254\n",
            "Train Epoch: 28 [40000/60000 (67%)]\tLoss: 154.922891\n",
            "Train Epoch: 28 [50000/60000 (83%)]\tLoss: 147.414541\n",
            "====> Epoch: 28 Average loss: 149.4978\n",
            "====> Test set loss: 151.0236\n",
            "Train Epoch: 29 [0/60000 (0%)]\tLoss: 151.249658\n",
            "Train Epoch: 29 [10000/60000 (17%)]\tLoss: 149.818242\n",
            "Train Epoch: 29 [20000/60000 (33%)]\tLoss: 144.621074\n",
            "Train Epoch: 29 [30000/60000 (50%)]\tLoss: 159.807109\n",
            "Train Epoch: 29 [40000/60000 (67%)]\tLoss: 153.397451\n",
            "Train Epoch: 29 [50000/60000 (83%)]\tLoss: 143.177842\n",
            "====> Epoch: 29 Average loss: 149.3817\n",
            "====> Test set loss: 151.0279\n",
            "Train Epoch: 30 [0/60000 (0%)]\tLoss: 144.951084\n",
            "Train Epoch: 30 [10000/60000 (17%)]\tLoss: 151.631885\n",
            "Train Epoch: 30 [20000/60000 (33%)]\tLoss: 146.590283\n",
            "Train Epoch: 30 [30000/60000 (50%)]\tLoss: 149.684160\n",
            "Train Epoch: 30 [40000/60000 (67%)]\tLoss: 143.748701\n",
            "Train Epoch: 30 [50000/60000 (83%)]\tLoss: 147.537695\n",
            "====> Epoch: 30 Average loss: 149.1758\n",
            "====> Test set loss: 151.0312\n",
            "Train Epoch: 31 [0/60000 (0%)]\tLoss: 142.889189\n",
            "Train Epoch: 31 [10000/60000 (17%)]\tLoss: 143.547773\n",
            "Train Epoch: 31 [20000/60000 (33%)]\tLoss: 147.381631\n",
            "Train Epoch: 31 [30000/60000 (50%)]\tLoss: 158.115039\n",
            "Train Epoch: 31 [40000/60000 (67%)]\tLoss: 150.716748\n",
            "Train Epoch: 31 [50000/60000 (83%)]\tLoss: 147.419961\n",
            "====> Epoch: 31 Average loss: 149.0244\n",
            "====> Test set loss: 150.9872\n",
            "Train Epoch: 32 [0/60000 (0%)]\tLoss: 142.329355\n",
            "Train Epoch: 32 [10000/60000 (17%)]\tLoss: 146.708857\n",
            "Train Epoch: 32 [20000/60000 (33%)]\tLoss: 155.356514\n",
            "Train Epoch: 32 [30000/60000 (50%)]\tLoss: 153.886904\n",
            "Train Epoch: 32 [40000/60000 (67%)]\tLoss: 147.839746\n",
            "Train Epoch: 32 [50000/60000 (83%)]\tLoss: 150.229883\n",
            "====> Epoch: 32 Average loss: 148.8459\n",
            "====> Test set loss: 150.9983\n",
            "Train Epoch: 33 [0/60000 (0%)]\tLoss: 151.833135\n",
            "Train Epoch: 33 [10000/60000 (17%)]\tLoss: 147.263457\n",
            "Train Epoch: 33 [20000/60000 (33%)]\tLoss: 156.693203\n",
            "Train Epoch: 33 [30000/60000 (50%)]\tLoss: 146.770000\n",
            "Train Epoch: 33 [40000/60000 (67%)]\tLoss: 150.228359\n",
            "Train Epoch: 33 [50000/60000 (83%)]\tLoss: 150.225068\n",
            "====> Epoch: 33 Average loss: 148.7732\n",
            "====> Test set loss: 150.5320\n",
            "Train Epoch: 34 [0/60000 (0%)]\tLoss: 139.320674\n",
            "Train Epoch: 34 [10000/60000 (17%)]\tLoss: 140.095654\n",
            "Train Epoch: 34 [20000/60000 (33%)]\tLoss: 151.192969\n",
            "Train Epoch: 34 [30000/60000 (50%)]\tLoss: 153.214297\n",
            "Train Epoch: 34 [40000/60000 (67%)]\tLoss: 149.232969\n",
            "Train Epoch: 34 [50000/60000 (83%)]\tLoss: 144.640830\n",
            "====> Epoch: 34 Average loss: 148.5832\n",
            "====> Test set loss: 150.5982\n",
            "Train Epoch: 35 [0/60000 (0%)]\tLoss: 149.224580\n",
            "Train Epoch: 35 [10000/60000 (17%)]\tLoss: 148.231719\n",
            "Train Epoch: 35 [20000/60000 (33%)]\tLoss: 150.612578\n",
            "Train Epoch: 35 [30000/60000 (50%)]\tLoss: 155.012080\n",
            "Train Epoch: 35 [40000/60000 (67%)]\tLoss: 158.080586\n",
            "Train Epoch: 35 [50000/60000 (83%)]\tLoss: 145.618457\n",
            "====> Epoch: 35 Average loss: 148.4455\n",
            "====> Test set loss: 150.1708\n",
            "Train Epoch: 36 [0/60000 (0%)]\tLoss: 148.156914\n",
            "Train Epoch: 36 [10000/60000 (17%)]\tLoss: 150.965791\n",
            "Train Epoch: 36 [20000/60000 (33%)]\tLoss: 149.517207\n",
            "Train Epoch: 36 [30000/60000 (50%)]\tLoss: 147.660576\n",
            "Train Epoch: 36 [40000/60000 (67%)]\tLoss: 147.919951\n",
            "Train Epoch: 36 [50000/60000 (83%)]\tLoss: 144.570508\n",
            "====> Epoch: 36 Average loss: 148.3118\n",
            "====> Test set loss: 150.3678\n",
            "Train Epoch: 37 [0/60000 (0%)]\tLoss: 148.033926\n",
            "Train Epoch: 37 [10000/60000 (17%)]\tLoss: 146.222227\n",
            "Train Epoch: 37 [20000/60000 (33%)]\tLoss: 149.285703\n",
            "Train Epoch: 37 [30000/60000 (50%)]\tLoss: 135.542764\n",
            "Train Epoch: 37 [40000/60000 (67%)]\tLoss: 145.762295\n",
            "Train Epoch: 37 [50000/60000 (83%)]\tLoss: 147.960156\n",
            "====> Epoch: 37 Average loss: 148.2129\n",
            "====> Test set loss: 150.2568\n",
            "Train Epoch: 38 [0/60000 (0%)]\tLoss: 153.315439\n",
            "Train Epoch: 38 [10000/60000 (17%)]\tLoss: 146.310996\n",
            "Train Epoch: 38 [20000/60000 (33%)]\tLoss: 145.075195\n",
            "Train Epoch: 38 [30000/60000 (50%)]\tLoss: 143.665195\n",
            "Train Epoch: 38 [40000/60000 (67%)]\tLoss: 147.426055\n",
            "Train Epoch: 38 [50000/60000 (83%)]\tLoss: 143.889746\n",
            "====> Epoch: 38 Average loss: 148.0891\n",
            "====> Test set loss: 149.9962\n",
            "Train Epoch: 39 [0/60000 (0%)]\tLoss: 142.140498\n",
            "Train Epoch: 39 [10000/60000 (17%)]\tLoss: 149.861895\n",
            "Train Epoch: 39 [20000/60000 (33%)]\tLoss: 145.811963\n",
            "Train Epoch: 39 [30000/60000 (50%)]\tLoss: 146.221270\n",
            "Train Epoch: 39 [40000/60000 (67%)]\tLoss: 142.721240\n",
            "Train Epoch: 39 [50000/60000 (83%)]\tLoss: 145.584219\n",
            "====> Epoch: 39 Average loss: 147.9429\n",
            "====> Test set loss: 150.1359\n",
            "Train Epoch: 40 [0/60000 (0%)]\tLoss: 151.585498\n",
            "Train Epoch: 40 [10000/60000 (17%)]\tLoss: 144.973379\n",
            "Train Epoch: 40 [20000/60000 (33%)]\tLoss: 147.347510\n",
            "Train Epoch: 40 [30000/60000 (50%)]\tLoss: 149.657090\n",
            "Train Epoch: 40 [40000/60000 (67%)]\tLoss: 138.351826\n",
            "Train Epoch: 40 [50000/60000 (83%)]\tLoss: 151.921836\n",
            "====> Epoch: 40 Average loss: 147.8577\n",
            "====> Test set loss: 150.1800\n",
            "Train Epoch: 41 [0/60000 (0%)]\tLoss: 147.678096\n",
            "Train Epoch: 41 [10000/60000 (17%)]\tLoss: 146.442178\n",
            "Train Epoch: 41 [20000/60000 (33%)]\tLoss: 145.419814\n",
            "Train Epoch: 41 [30000/60000 (50%)]\tLoss: 144.541885\n",
            "Train Epoch: 41 [40000/60000 (67%)]\tLoss: 149.671367\n",
            "Train Epoch: 41 [50000/60000 (83%)]\tLoss: 146.222217\n",
            "====> Epoch: 41 Average loss: 147.6943\n",
            "====> Test set loss: 150.2001\n",
            "Train Epoch: 42 [0/60000 (0%)]\tLoss: 154.478643\n",
            "Train Epoch: 42 [10000/60000 (17%)]\tLoss: 137.583584\n",
            "Train Epoch: 42 [20000/60000 (33%)]\tLoss: 147.421055\n",
            "Train Epoch: 42 [30000/60000 (50%)]\tLoss: 149.673799\n",
            "Train Epoch: 42 [40000/60000 (67%)]\tLoss: 147.031025\n",
            "Train Epoch: 42 [50000/60000 (83%)]\tLoss: 143.321201\n",
            "====> Epoch: 42 Average loss: 147.6198\n",
            "====> Test set loss: 149.8333\n",
            "Train Epoch: 43 [0/60000 (0%)]\tLoss: 150.330566\n",
            "Train Epoch: 43 [10000/60000 (17%)]\tLoss: 143.375215\n",
            "Train Epoch: 43 [20000/60000 (33%)]\tLoss: 149.941777\n",
            "Train Epoch: 43 [30000/60000 (50%)]\tLoss: 148.594932\n",
            "Train Epoch: 43 [40000/60000 (67%)]\tLoss: 149.066094\n",
            "Train Epoch: 43 [50000/60000 (83%)]\tLoss: 145.053506\n",
            "====> Epoch: 43 Average loss: 147.5190\n",
            "====> Test set loss: 149.6578\n",
            "Train Epoch: 44 [0/60000 (0%)]\tLoss: 139.070977\n",
            "Train Epoch: 44 [10000/60000 (17%)]\tLoss: 143.025430\n",
            "Train Epoch: 44 [20000/60000 (33%)]\tLoss: 149.119951\n",
            "Train Epoch: 44 [30000/60000 (50%)]\tLoss: 144.074199\n",
            "Train Epoch: 44 [40000/60000 (67%)]\tLoss: 141.785342\n",
            "Train Epoch: 44 [50000/60000 (83%)]\tLoss: 145.637637\n",
            "====> Epoch: 44 Average loss: 147.4053\n",
            "====> Test set loss: 149.7884\n",
            "Train Epoch: 45 [0/60000 (0%)]\tLoss: 139.780244\n",
            "Train Epoch: 45 [10000/60000 (17%)]\tLoss: 144.547480\n",
            "Train Epoch: 45 [20000/60000 (33%)]\tLoss: 151.293271\n",
            "Train Epoch: 45 [30000/60000 (50%)]\tLoss: 150.919482\n",
            "Train Epoch: 45 [40000/60000 (67%)]\tLoss: 143.037754\n",
            "Train Epoch: 45 [50000/60000 (83%)]\tLoss: 154.801240\n",
            "====> Epoch: 45 Average loss: 147.3022\n",
            "====> Test set loss: 149.6096\n",
            "Train Epoch: 46 [0/60000 (0%)]\tLoss: 148.091348\n",
            "Train Epoch: 46 [10000/60000 (17%)]\tLoss: 145.059961\n",
            "Train Epoch: 46 [20000/60000 (33%)]\tLoss: 139.025088\n",
            "Train Epoch: 46 [30000/60000 (50%)]\tLoss: 144.250381\n",
            "Train Epoch: 46 [40000/60000 (67%)]\tLoss: 143.455205\n",
            "Train Epoch: 46 [50000/60000 (83%)]\tLoss: 146.567861\n",
            "====> Epoch: 46 Average loss: 147.1864\n",
            "====> Test set loss: 149.7062\n",
            "Train Epoch: 47 [0/60000 (0%)]\tLoss: 144.846494\n",
            "Train Epoch: 47 [10000/60000 (17%)]\tLoss: 151.520244\n",
            "Train Epoch: 47 [20000/60000 (33%)]\tLoss: 147.411035\n",
            "Train Epoch: 47 [30000/60000 (50%)]\tLoss: 151.636123\n",
            "Train Epoch: 47 [40000/60000 (67%)]\tLoss: 143.528984\n",
            "Train Epoch: 47 [50000/60000 (83%)]\tLoss: 143.636211\n",
            "====> Epoch: 47 Average loss: 147.1000\n",
            "====> Test set loss: 149.7241\n",
            "Train Epoch: 48 [0/60000 (0%)]\tLoss: 148.163242\n",
            "Train Epoch: 48 [10000/60000 (17%)]\tLoss: 153.714922\n",
            "Train Epoch: 48 [20000/60000 (33%)]\tLoss: 153.272598\n",
            "Train Epoch: 48 [30000/60000 (50%)]\tLoss: 141.066992\n",
            "Train Epoch: 48 [40000/60000 (67%)]\tLoss: 142.916113\n",
            "Train Epoch: 48 [50000/60000 (83%)]\tLoss: 138.729434\n",
            "====> Epoch: 48 Average loss: 147.0116\n",
            "====> Test set loss: 149.8163\n",
            "Train Epoch: 49 [0/60000 (0%)]\tLoss: 142.430869\n",
            "Train Epoch: 49 [10000/60000 (17%)]\tLoss: 145.909141\n",
            "Train Epoch: 49 [20000/60000 (33%)]\tLoss: 140.604697\n",
            "Train Epoch: 49 [30000/60000 (50%)]\tLoss: 152.392148\n",
            "Train Epoch: 49 [40000/60000 (67%)]\tLoss: 141.553984\n",
            "Train Epoch: 49 [50000/60000 (83%)]\tLoss: 157.088174\n",
            "====> Epoch: 49 Average loss: 146.9678\n",
            "====> Test set loss: 149.9289\n",
            "Train Epoch: 50 [0/60000 (0%)]\tLoss: 143.398887\n",
            "Train Epoch: 50 [10000/60000 (17%)]\tLoss: 142.046611\n",
            "Train Epoch: 50 [20000/60000 (33%)]\tLoss: 140.180225\n",
            "Train Epoch: 50 [30000/60000 (50%)]\tLoss: 150.088164\n",
            "Train Epoch: 50 [40000/60000 (67%)]\tLoss: 143.382578\n",
            "Train Epoch: 50 [50000/60000 (83%)]\tLoss: 143.140889\n",
            "====> Epoch: 50 Average loss: 146.7958\n",
            "====> Test set loss: 149.4361\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqAhB6FXGyhY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "0064b58d-0f1b-47cc-b5c7-6cc505ee3282"
      },
      "source": [
        "# test_Loss_Contain\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "plt.plot(test_Loss_Contain)\n",
        "plt.xlabel(\"VAE Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0IrZuTcvSEI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b0f02aa4a8a14da6b0dc5b328c20684e",
            "5971475963a8401db2ce1a79ee9e7785",
            "8b18b54c95b64664aee4283ade753cfd",
            "9af7026eb73648018fe7b9d1b539cc04",
            "e13350cba21147f488711461a6dabf70",
            "da07da8bf484437e960fbe044391fa02",
            "240ba7e7957342909fe0661186c020a2",
            "551a0f913da545d0b42ed3d28d378869",
            "7f6311ff54a647fcbc1287e948b907df",
            "15bc78a97f484678a87eb720d3839d55",
            "d3cde0892d704bb18029d2c4cfb46f1d",
            "58fd53aeee494b828a7f638425db4598",
            "0402bbf36057467d8a97f197e5b767ef",
            "3c3927ebed3448b3b7b45618f2a3d65f",
            "5e12e1f2354d4ab382704399bb3794d4",
            "e6d9870efd774af98ab4ef8f68cb02f6",
            "9660f3bcccbe4b85854c513f8f4b76ca",
            "e692ab4dbe364282a69596f202b79dc4",
            "21d189307be64773a43fecaeb4d049bc",
            "bf0fbc24664948b49e9e7e2e205f8ce3",
            "1f5784c58aaf43cfabd8f11fa85dc831",
            "5d1198a642224c1a8e6565193490a215",
            "b76723815e394c5ab1bb57cdee1ac02f",
            "af2808b60fc44e4da86c1ced45d4b77d",
            "9d7f549b1fb147dfa8b2268ed6f7f936",
            "4fea4144fd0949dbb506fd25b191194c",
            "63e07891f0174ebd9b87905af10aeb34",
            "1716fda62c3b41efafb52169a0c1f2bd",
            "2dcbe31fecf44577b3dd06b5f8081d30",
            "9c7be44704454ddc91956b76953135e7",
            "a1b1169e01c346d0bcf914359fb230a2",
            "28d892ad8def4dbc8e6206b400d33fa9"
          ]
        },
        "outputId": "e261f7e2-644f-428b-d09e-6b2212e12b7c"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"GAN_MNIST.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1KMVZC_qMZl2wBl573u-q6StWRWfC9z6C\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# number of subprocesses to use for data loading\n",
        "num_workers = 0\n",
        "# how many samples per batch to load\n",
        "batch_size = 64\n",
        "\n",
        "# convert data to torch.FloatTensor\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "# get the training datasets\n",
        "train_data = datasets.MNIST(root='data', train=True,\n",
        "                                   download=True, transform=transform)\n",
        "print(train_data)\n",
        "\n",
        "# prepare data loader\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
        "                                           num_workers=num_workers)\n",
        "\n",
        "# obtain one batch of training images\n",
        "# dataiter = iter(train_loader)\n",
        "# images, labels = dataiter.next()\n",
        "# images = images.numpy()\n",
        "\n",
        "# # get one image from the batch\n",
        "# img = np.squeeze(images[0])\n",
        "\n",
        "# fig = plt.figure(figsize = (3,3)) \n",
        "# ax = fig.add_subplot(111)\n",
        "# ax.imshow(img, cmap='gray')\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_dim, output_size):\n",
        "        super(Discriminator, self).__init__()\n",
        "        \n",
        "        # define hidden linear layers\n",
        "        self.fc1 = nn.Linear(input_size, hidden_dim*4)\n",
        "        self.fc2 = nn.Linear(hidden_dim*4, hidden_dim*2)\n",
        "        self.fc3 = nn.Linear(hidden_dim*2, hidden_dim)\n",
        "        \n",
        "        # final fully-connected layer\n",
        "        self.fc4 = nn.Linear( hidden_dim, output_size)\n",
        "        \n",
        "        # dropout layer \n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "        # flatten image\n",
        "        x = x.view(-1, 28*28)\n",
        "        # all hidden layers\n",
        "        x = F.leaky_relu(self.fc1(x), 0.2) # (input, negative_slope=0.2)\n",
        "        x = self.dropout(x)\n",
        "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
        "        x = self.dropout(x)\n",
        "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
        "        x = self.dropout(x)\n",
        "        # final layer\n",
        "        out = self.fc4(x)\n",
        "\n",
        "        return out\n",
        "\n",
        "class Generator(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_dim, output_size):\n",
        "        super(Generator, self).__init__()\n",
        "        \n",
        "        # define hidden linear layers\n",
        "        self.fc1 = nn.Linear(input_size, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim*2)\n",
        "        self.fc3 = nn.Linear(hidden_dim*2, hidden_dim*4)\n",
        "        \n",
        "        # final fully-connected layer\n",
        "        self.fc4 = nn.Linear(hidden_dim*4, output_size)\n",
        "        \n",
        "        # dropout layer \n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # all hidden layers\n",
        "        x = F.leaky_relu(self.fc1(x), 0.2) # (input, negative_slope=0.2)\n",
        "        x = self.dropout(x)\n",
        "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
        "        x = self.dropout(x)\n",
        "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
        "        x = self.dropout(x)\n",
        "        # final layer with tanh applied\n",
        "        out = F.tanh(self.fc4(x))\n",
        "\n",
        "        return out\n",
        "\n",
        "# Discriminator hyperparams\n",
        "\n",
        "# Size of input image to discriminator (28*28)\n",
        "input_size = 784\n",
        "# Size of discriminator output (real or fake)\n",
        "d_output_size = 1\n",
        "# Size of last hidden layer in the discriminator\n",
        "d_hidden_size = 32\n",
        "\n",
        "# Generator hyperparams\n",
        "\n",
        "# Size of latent vector to give to generator\n",
        "z_size = 100\n",
        "# Size of discriminator output (generated image)\n",
        "g_output_size = 784\n",
        "# Size of first hidden layer in the generator\n",
        "g_hidden_size = 32\n",
        "\n",
        "# instantiate discriminator and generator\n",
        "D = Discriminator(input_size, d_hidden_size, d_output_size)\n",
        "G = Generator(z_size, g_hidden_size, g_output_size)\n",
        "\n",
        "# check that they are as you expect\n",
        "print(D)\n",
        "print()\n",
        "print(G)\n",
        "\n",
        "# Calculate losses\n",
        "def real_loss(D_out, smooth=False):\n",
        "    batch_size = D_out.size(0)\n",
        "    # label smoothing\n",
        "    if smooth:\n",
        "        # smooth, real labels = 0.9\n",
        "        labels = torch.ones(batch_size)*0.9\n",
        "    else:\n",
        "        labels = torch.ones(batch_size) # real labels = 1\n",
        "        \n",
        "    # numerically stable loss\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    # calculate loss\n",
        "    loss = criterion(D_out.squeeze(), labels)\n",
        "    return loss\n",
        "\n",
        "def fake_loss(D_out):\n",
        "    batch_size = D_out.size(0)\n",
        "    labels = torch.zeros(batch_size) # fake labels = 0\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    # calculate loss\n",
        "    loss = criterion(D_out.squeeze(), labels)\n",
        "    return loss\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "# Optimizers\n",
        "lr = 0.002\n",
        "\n",
        "# Create optimizers for the discriminator and generator\n",
        "d_optimizer = optim.Adam(D.parameters(), lr)\n",
        "g_optimizer = optim.Adam(G.parameters(), lr)\n",
        "\n",
        "import pickle as pkl\n",
        "\n",
        "# training hyperparams\n",
        "num_epochs = 100\n",
        "\n",
        "# keep track of loss and generated, \"fake\" samples\n",
        "samples = []\n",
        "losses = []\n",
        "\n",
        "print_every = 400\n",
        "\n",
        "# Get some fixed data for sampling. These are images that are held\n",
        "# constant throughout training, and allow us to inspect the model's performance\n",
        "sample_size=16\n",
        "fixed_z = np.random.uniform(-1, 1, size=(sample_size, z_size))\n",
        "fixed_z = torch.from_numpy(fixed_z).float()\n",
        "\n",
        "# train the network\n",
        "D.train()\n",
        "G.train()\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    for batch_i, (real_images, _) in enumerate(train_loader):\n",
        "                \n",
        "        batch_size = real_images.size(0)\n",
        "        \n",
        "        ## Important rescaling step ## \n",
        "        real_images = real_images*2 - 1  # rescale input images from [0,1) to [-1, 1)\n",
        "        \n",
        "        # ============================================\n",
        "        #            TRAIN THE DISCRIMINATOR\n",
        "        # ============================================\n",
        "        \n",
        "        d_optimizer.zero_grad()\n",
        "        \n",
        "        # 1. Train with real images\n",
        "\n",
        "        # Compute the discriminator losses on real images \n",
        "        # smooth the real labels\n",
        "        D_real = D(real_images)\n",
        "        d_real_loss = real_loss(D_real, smooth=True)\n",
        "        \n",
        "        # 2. Train with fake images\n",
        "        \n",
        "        # Generate fake images\n",
        "        z = np.random.uniform(-1, 1, size=(batch_size, z_size))\n",
        "        z = torch.from_numpy(z).float()\n",
        "        fake_images = G(z)\n",
        "        \n",
        "        # Compute the discriminator losses on fake images        \n",
        "        D_fake = D(fake_images)\n",
        "        d_fake_loss = fake_loss(D_fake)\n",
        "        \n",
        "        # add up loss and perform backprop\n",
        "        d_loss = d_real_loss + d_fake_loss\n",
        "        d_loss.backward()\n",
        "        d_optimizer.step()\n",
        "        \n",
        "        \n",
        "        # =========================================\n",
        "        #            TRAIN THE GENERATOR\n",
        "        # =========================================\n",
        "        g_optimizer.zero_grad()\n",
        "        \n",
        "        # 1. Train with fake images and flipped labels\n",
        "        \n",
        "        # Generate fake images\n",
        "        z = np.random.uniform(-1, 1, size=(batch_size, z_size))\n",
        "        z = torch.from_numpy(z).float()\n",
        "        fake_images = G(z)\n",
        "        \n",
        "        # Compute the discriminator losses on fake images \n",
        "        # using flipped labels!\n",
        "        D_fake = D(fake_images)\n",
        "        g_loss = real_loss(D_fake) # use real loss to flip labels\n",
        "        \n",
        "        # perform backprop\n",
        "        g_loss.backward()\n",
        "        g_optimizer.step()\n",
        "\n",
        "        # Print some loss stats\n",
        "        if batch_i % print_every == 0:\n",
        "            # print discriminator and generator loss\n",
        "            print('Epoch [{:5d}/{:5d}] | d_loss: {:6.4f} | g_loss: {:6.4f}'.format(\n",
        "                    epoch+1, num_epochs, d_loss.item(), g_loss.item()))\n",
        "\n",
        "    \n",
        "    ## AFTER EACH EPOCH##\n",
        "    # append discriminator loss and generator loss\n",
        "    losses.append((d_loss.item(), g_loss.item()))\n",
        "    \n",
        "    # generate and save sample, fake images\n",
        "    G.eval() # eval mode for generating samples\n",
        "    samples_z = G(fixed_z)\n",
        "    samples.append(samples_z)\n",
        "    G.train() # back to train mode\n",
        "\n",
        "\n",
        "# Save training generator samples\n",
        "with open('train_samples.pkl', 'wb') as f:\n",
        "    pkl.dump(samples, f)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "losses = np.array(losses)\n",
        "plt.plot(losses.T[0], label='Discriminator')\n",
        "plt.plot(losses.T[1], label='Generator')\n",
        "plt.title(\"Training Losses\")\n",
        "plt.legend()\n",
        "\n",
        "# helper function for viewing a list of passed in sample images\n",
        "def view_samples(epoch, samples):\n",
        "    fig, axes = plt.subplots(figsize=(7,7), nrows=4, ncols=4, sharey=True, sharex=True)\n",
        "    for ax, img in zip(axes.flatten(), samples[epoch]):\n",
        "        img = img.detach()\n",
        "        ax.xaxis.set_visible(False)\n",
        "        ax.yaxis.set_visible(False)\n",
        "        im = ax.imshow(img.reshape((28,28)), cmap='Greys_r')\n",
        "\n",
        "# Load samples from generator, taken while training\n",
        "with open('train_samples.pkl', 'rb') as f:\n",
        "    samples = pkl.load(f)\n",
        "\n",
        "# -1 indicates final epoch's samples (the last in the list)\n",
        "view_samples(-1, samples)\n",
        "\n",
        "rows = 10 # split epochs into 10, so 100/10 = every 10 epochs\n",
        "cols = 6\n",
        "fig, axes = plt.subplots(figsize=(7,12), nrows=rows, ncols=cols, sharex=True, sharey=True)\n",
        "\n",
        "for sample, ax_row in zip(samples[::int(len(samples)/rows)], axes):\n",
        "    for img, ax in zip(sample[::int(len(sample)/cols)], ax_row):\n",
        "        img = img.detach()\n",
        "        ax.imshow(img.reshape((28,28)), cmap='Greys_r')\n",
        "        ax.xaxis.set_visible(False)\n",
        "        ax.yaxis.set_visible(False)\n",
        "\n",
        "# randomly generated, new latent vectors\n",
        "sample_size=16\n",
        "rand_z = np.random.uniform(-1, 1, size=(sample_size, z_size))\n",
        "rand_z = torch.from_numpy(rand_z).float()\n",
        "\n",
        "G.eval() # eval mode\n",
        "# generated samples\n",
        "rand_images = G(rand_z)\n",
        "\n",
        "# 0 indicates the first set of samples in the passed in list\n",
        "# and we only have one batch of samples, here\n",
        "view_samples(0, [rand_images])\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b0f02aa4a8a14da6b0dc5b328c20684e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7f6311ff54a647fcbc1287e948b907df",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9660f3bcccbe4b85854c513f8f4b76ca",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9d7f549b1fb147dfa8b2268ed6f7f936",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "Processing...\n",
            "Done!\n",
            "Dataset MNIST\n",
            "    Number of datapoints: 60000\n",
            "    Root location: data\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: ToTensor()\n",
            "Discriminator(\n",
            "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (fc3): Linear(in_features=64, out_features=32, bias=True)\n",
            "  (fc4): Linear(in_features=32, out_features=1, bias=True)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            ")\n",
            "\n",
            "Generator(\n",
            "  (fc1): Linear(in_features=100, out_features=32, bias=True)\n",
            "  (fc2): Linear(in_features=32, out_features=64, bias=True)\n",
            "  (fc3): Linear(in_features=64, out_features=128, bias=True)\n",
            "  (fc4): Linear(in_features=128, out_features=784, bias=True)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            ")\n",
            "Epoch [    1/  100] | d_loss: 1.3914 | g_loss: 0.7405\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch [    1/  100] | d_loss: 1.2191 | g_loss: 1.5249\n",
            "Epoch [    1/  100] | d_loss: 1.7341 | g_loss: 0.4560\n",
            "Epoch [    2/  100] | d_loss: 1.3474 | g_loss: 0.9387\n",
            "Epoch [    2/  100] | d_loss: 1.3492 | g_loss: 0.8556\n",
            "Epoch [    2/  100] | d_loss: 1.3307 | g_loss: 0.7354\n",
            "Epoch [    3/  100] | d_loss: 1.4725 | g_loss: 0.8781\n",
            "Epoch [    3/  100] | d_loss: 0.7642 | g_loss: 2.8887\n",
            "Epoch [    3/  100] | d_loss: 1.2149 | g_loss: 2.4986\n",
            "Epoch [    4/  100] | d_loss: 0.7694 | g_loss: 3.8972\n",
            "Epoch [    4/  100] | d_loss: 1.1837 | g_loss: 1.3864\n",
            "Epoch [    4/  100] | d_loss: 1.2953 | g_loss: 1.6081\n",
            "Epoch [    5/  100] | d_loss: 0.9908 | g_loss: 2.1887\n",
            "Epoch [    5/  100] | d_loss: 1.0419 | g_loss: 1.9381\n",
            "Epoch [    5/  100] | d_loss: 1.1748 | g_loss: 2.0467\n",
            "Epoch [    6/  100] | d_loss: 1.1489 | g_loss: 1.1346\n",
            "Epoch [    6/  100] | d_loss: 1.1835 | g_loss: 1.1832\n",
            "Epoch [    6/  100] | d_loss: 1.4283 | g_loss: 0.8925\n",
            "Epoch [    7/  100] | d_loss: 1.4869 | g_loss: 0.6887\n",
            "Epoch [    7/  100] | d_loss: 1.2412 | g_loss: 1.3026\n",
            "Epoch [    7/  100] | d_loss: 1.2993 | g_loss: 1.0947\n",
            "Epoch [    8/  100] | d_loss: 1.2589 | g_loss: 1.1591\n",
            "Epoch [    8/  100] | d_loss: 1.2690 | g_loss: 1.1188\n",
            "Epoch [    8/  100] | d_loss: 1.2811 | g_loss: 1.2229\n",
            "Epoch [    9/  100] | d_loss: 1.2357 | g_loss: 1.4380\n",
            "Epoch [    9/  100] | d_loss: 1.1561 | g_loss: 1.6950\n",
            "Epoch [    9/  100] | d_loss: 1.3450 | g_loss: 0.9098\n",
            "Epoch [   10/  100] | d_loss: 1.3723 | g_loss: 1.3576\n",
            "Epoch [   10/  100] | d_loss: 1.1863 | g_loss: 1.1224\n",
            "Epoch [   10/  100] | d_loss: 1.1489 | g_loss: 1.4653\n",
            "Epoch [   11/  100] | d_loss: 1.2223 | g_loss: 0.8018\n",
            "Epoch [   11/  100] | d_loss: 1.2006 | g_loss: 1.1927\n",
            "Epoch [   11/  100] | d_loss: 1.1500 | g_loss: 1.4001\n",
            "Epoch [   12/  100] | d_loss: 1.2286 | g_loss: 1.4435\n",
            "Epoch [   12/  100] | d_loss: 1.0930 | g_loss: 1.0839\n",
            "Epoch [   12/  100] | d_loss: 1.3517 | g_loss: 1.0552\n",
            "Epoch [   13/  100] | d_loss: 1.2516 | g_loss: 0.9321\n",
            "Epoch [   13/  100] | d_loss: 1.3347 | g_loss: 0.9835\n",
            "Epoch [   13/  100] | d_loss: 1.3485 | g_loss: 0.9758\n",
            "Epoch [   14/  100] | d_loss: 1.3251 | g_loss: 1.4152\n",
            "Epoch [   14/  100] | d_loss: 1.1141 | g_loss: 1.1229\n",
            "Epoch [   14/  100] | d_loss: 1.3952 | g_loss: 0.7868\n",
            "Epoch [   15/  100] | d_loss: 1.1379 | g_loss: 1.2495\n",
            "Epoch [   15/  100] | d_loss: 1.2486 | g_loss: 1.3177\n",
            "Epoch [   15/  100] | d_loss: 1.2289 | g_loss: 1.0549\n",
            "Epoch [   16/  100] | d_loss: 1.2652 | g_loss: 1.4311\n",
            "Epoch [   16/  100] | d_loss: 1.2241 | g_loss: 1.0902\n",
            "Epoch [   16/  100] | d_loss: 1.2661 | g_loss: 1.1540\n",
            "Epoch [   17/  100] | d_loss: 1.2548 | g_loss: 1.0959\n",
            "Epoch [   17/  100] | d_loss: 1.1211 | g_loss: 1.3100\n",
            "Epoch [   17/  100] | d_loss: 1.3689 | g_loss: 0.8831\n",
            "Epoch [   18/  100] | d_loss: 1.2825 | g_loss: 0.9748\n",
            "Epoch [   18/  100] | d_loss: 1.2855 | g_loss: 1.0249\n",
            "Epoch [   18/  100] | d_loss: 1.2971 | g_loss: 1.2700\n",
            "Epoch [   19/  100] | d_loss: 1.3599 | g_loss: 0.9287\n",
            "Epoch [   19/  100] | d_loss: 1.1613 | g_loss: 1.4784\n",
            "Epoch [   19/  100] | d_loss: 1.2571 | g_loss: 1.0330\n",
            "Epoch [   20/  100] | d_loss: 1.3031 | g_loss: 0.8512\n",
            "Epoch [   20/  100] | d_loss: 1.2390 | g_loss: 0.9740\n",
            "Epoch [   20/  100] | d_loss: 1.2493 | g_loss: 1.3563\n",
            "Epoch [   21/  100] | d_loss: 1.4234 | g_loss: 1.1001\n",
            "Epoch [   21/  100] | d_loss: 1.1806 | g_loss: 1.0552\n",
            "Epoch [   21/  100] | d_loss: 1.3268 | g_loss: 1.0312\n",
            "Epoch [   22/  100] | d_loss: 1.2541 | g_loss: 0.9128\n",
            "Epoch [   22/  100] | d_loss: 1.1759 | g_loss: 1.3717\n",
            "Epoch [   22/  100] | d_loss: 1.1524 | g_loss: 1.4246\n",
            "Epoch [   23/  100] | d_loss: 1.2761 | g_loss: 1.2204\n",
            "Epoch [   23/  100] | d_loss: 1.2793 | g_loss: 1.2677\n",
            "Epoch [   23/  100] | d_loss: 1.3935 | g_loss: 0.9896\n",
            "Epoch [   24/  100] | d_loss: 1.2481 | g_loss: 1.0749\n",
            "Epoch [   24/  100] | d_loss: 1.2820 | g_loss: 1.0354\n",
            "Epoch [   24/  100] | d_loss: 1.3262 | g_loss: 0.9016\n",
            "Epoch [   25/  100] | d_loss: 1.1776 | g_loss: 1.2659\n",
            "Epoch [   25/  100] | d_loss: 1.1440 | g_loss: 1.1579\n",
            "Epoch [   25/  100] | d_loss: 1.2881 | g_loss: 1.0345\n",
            "Epoch [   26/  100] | d_loss: 1.3402 | g_loss: 1.1508\n",
            "Epoch [   26/  100] | d_loss: 1.3463 | g_loss: 0.9038\n",
            "Epoch [   26/  100] | d_loss: 1.2926 | g_loss: 1.1888\n",
            "Epoch [   27/  100] | d_loss: 1.2485 | g_loss: 1.4700\n",
            "Epoch [   27/  100] | d_loss: 1.2778 | g_loss: 0.9773\n",
            "Epoch [   27/  100] | d_loss: 1.3077 | g_loss: 1.3247\n",
            "Epoch [   28/  100] | d_loss: 1.4210 | g_loss: 1.5775\n",
            "Epoch [   28/  100] | d_loss: 1.1842 | g_loss: 1.5265\n",
            "Epoch [   28/  100] | d_loss: 1.3100 | g_loss: 1.0839\n",
            "Epoch [   29/  100] | d_loss: 1.3573 | g_loss: 0.8960\n",
            "Epoch [   29/  100] | d_loss: 1.2583 | g_loss: 0.9415\n",
            "Epoch [   29/  100] | d_loss: 1.3018 | g_loss: 0.9796\n",
            "Epoch [   30/  100] | d_loss: 1.3242 | g_loss: 0.8396\n",
            "Epoch [   30/  100] | d_loss: 1.2415 | g_loss: 1.1375\n",
            "Epoch [   30/  100] | d_loss: 1.2326 | g_loss: 1.2989\n",
            "Epoch [   31/  100] | d_loss: 1.3481 | g_loss: 0.9488\n",
            "Epoch [   31/  100] | d_loss: 1.3175 | g_loss: 0.9140\n",
            "Epoch [   31/  100] | d_loss: 1.2559 | g_loss: 0.8935\n",
            "Epoch [   32/  100] | d_loss: 1.2741 | g_loss: 1.2747\n",
            "Epoch [   32/  100] | d_loss: 1.3128 | g_loss: 1.1461\n",
            "Epoch [   32/  100] | d_loss: 1.2431 | g_loss: 0.9993\n",
            "Epoch [   33/  100] | d_loss: 1.3331 | g_loss: 1.4941\n",
            "Epoch [   33/  100] | d_loss: 1.2532 | g_loss: 1.1150\n",
            "Epoch [   33/  100] | d_loss: 1.3309 | g_loss: 0.8673\n",
            "Epoch [   34/  100] | d_loss: 1.2529 | g_loss: 1.0223\n",
            "Epoch [   34/  100] | d_loss: 1.2765 | g_loss: 1.5699\n",
            "Epoch [   34/  100] | d_loss: 1.3391 | g_loss: 0.8540\n",
            "Epoch [   35/  100] | d_loss: 1.2394 | g_loss: 1.0623\n",
            "Epoch [   35/  100] | d_loss: 1.2617 | g_loss: 0.9872\n",
            "Epoch [   35/  100] | d_loss: 1.2743 | g_loss: 0.9252\n",
            "Epoch [   36/  100] | d_loss: 1.2140 | g_loss: 1.6759\n",
            "Epoch [   36/  100] | d_loss: 1.1928 | g_loss: 1.5158\n",
            "Epoch [   36/  100] | d_loss: 1.2171 | g_loss: 1.4625\n",
            "Epoch [   37/  100] | d_loss: 1.3446 | g_loss: 0.9578\n",
            "Epoch [   37/  100] | d_loss: 1.3560 | g_loss: 0.8880\n",
            "Epoch [   37/  100] | d_loss: 1.3168 | g_loss: 1.0518\n",
            "Epoch [   38/  100] | d_loss: 1.2514 | g_loss: 0.9658\n",
            "Epoch [   38/  100] | d_loss: 1.3285 | g_loss: 0.9995\n",
            "Epoch [   38/  100] | d_loss: 1.1810 | g_loss: 0.8919\n",
            "Epoch [   39/  100] | d_loss: 1.2774 | g_loss: 1.0191\n",
            "Epoch [   39/  100] | d_loss: 1.2378 | g_loss: 0.8816\n",
            "Epoch [   39/  100] | d_loss: 1.3400 | g_loss: 1.0094\n",
            "Epoch [   40/  100] | d_loss: 1.2028 | g_loss: 1.3130\n",
            "Epoch [   40/  100] | d_loss: 1.1989 | g_loss: 1.0074\n",
            "Epoch [   40/  100] | d_loss: 1.3706 | g_loss: 0.9382\n",
            "Epoch [   41/  100] | d_loss: 1.4254 | g_loss: 0.8762\n",
            "Epoch [   41/  100] | d_loss: 1.2987 | g_loss: 1.0103\n",
            "Epoch [   41/  100] | d_loss: 1.2804 | g_loss: 1.1980\n",
            "Epoch [   42/  100] | d_loss: 1.2404 | g_loss: 0.9415\n",
            "Epoch [   42/  100] | d_loss: 1.2165 | g_loss: 1.1958\n",
            "Epoch [   42/  100] | d_loss: 1.3570 | g_loss: 0.9733\n",
            "Epoch [   43/  100] | d_loss: 1.3097 | g_loss: 1.1415\n",
            "Epoch [   43/  100] | d_loss: 1.2597 | g_loss: 0.8054\n",
            "Epoch [   43/  100] | d_loss: 1.3316 | g_loss: 0.9732\n",
            "Epoch [   44/  100] | d_loss: 1.3188 | g_loss: 1.3343\n",
            "Epoch [   44/  100] | d_loss: 1.2113 | g_loss: 1.0144\n",
            "Epoch [   44/  100] | d_loss: 1.4081 | g_loss: 1.1095\n",
            "Epoch [   45/  100] | d_loss: 1.2879 | g_loss: 0.8974\n",
            "Epoch [   45/  100] | d_loss: 1.3251 | g_loss: 0.8815\n",
            "Epoch [   45/  100] | d_loss: 1.3671 | g_loss: 1.0745\n",
            "Epoch [   46/  100] | d_loss: 1.3268 | g_loss: 0.9919\n",
            "Epoch [   46/  100] | d_loss: 1.1527 | g_loss: 1.1906\n",
            "Epoch [   46/  100] | d_loss: 1.3462 | g_loss: 0.9776\n",
            "Epoch [   47/  100] | d_loss: 1.2694 | g_loss: 1.0144\n",
            "Epoch [   47/  100] | d_loss: 1.3270 | g_loss: 1.0361\n",
            "Epoch [   47/  100] | d_loss: 1.3434 | g_loss: 1.0642\n",
            "Epoch [   48/  100] | d_loss: 1.2830 | g_loss: 1.3743\n",
            "Epoch [   48/  100] | d_loss: 1.2473 | g_loss: 1.3660\n",
            "Epoch [   48/  100] | d_loss: 1.2606 | g_loss: 0.9397\n",
            "Epoch [   49/  100] | d_loss: 1.2868 | g_loss: 1.5129\n",
            "Epoch [   49/  100] | d_loss: 1.2608 | g_loss: 1.2346\n",
            "Epoch [   49/  100] | d_loss: 1.3359 | g_loss: 1.2515\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-30141be587c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;31m# Compute the discriminator losses on fake images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;31m# using flipped labels!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0mD_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m         \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreal_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_fake\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# use real loss to flip labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-30141be587c4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;31m# all hidden layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (input, negative_slope=0.2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/dropout.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m    981\u001b[0m     return (_VF.dropout_(input, p, training)\n\u001b[1;32m    982\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 983\u001b[0;31m             else _VF.dropout(input, p, training))\n\u001b[0m\u001b[1;32m    984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_VF.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_VariableFunctions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnOUvHVJvWDY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}