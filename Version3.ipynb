{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Version3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "byw6UtSr8qwG"
      },
      "source": [
        "# prerequisites\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch.optim as optim\r\n",
        "from torchvision import datasets, transforms\r\n",
        "from torch.autograd import Variable\r\n",
        "from torchvision.utils import save_image\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "# Device configuration\r\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
        "\r\n",
        " bs = 100\r\n",
        "\r\n",
        "# MNIST Dataset\r\n",
        "transform = transforms.Compose([\r\n",
        "    transforms.ToTensor(),\r\n",
        "    transforms.Normalize(mean=(0.5,), std=(0.5,))])\r\n",
        "\r\n",
        "train_dataset = datasets.MNIST(root='./mnist_data/', train=True, transform=transform, download=True)\r\n",
        "test_dataset = datasets.MNIST(root='./mnist_data/', train=False, transform=transform, download=False)\r\n",
        "\r\n",
        "# Data Loader (Input Pipeline)\r\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=bs, shuffle=True)\r\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=bs, shuffle=False)\r\n",
        "\r\n",
        "class Generator(nn.Module):\r\n",
        "    def __init__(self, g_input_dim, g_output_dim):\r\n",
        "        super(Generator, self).__init__()       \r\n",
        "        self.fc1 = nn.Linear(g_input_dim, 256)\r\n",
        "        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features*2)\r\n",
        "        self.fc4 = nn.Linear(self.fc2.out_features, g_output_dim)\r\n",
        "    \r\n",
        "    # forward method\r\n",
        "    def forward(self, x): \r\n",
        "        x = F.leaky_relu(self.fc1(x), 0.2)\r\n",
        "        x = F.leaky_relu(self.fc2(x), 0.2)\r\n",
        "        return torch.tanh(self.fc4(x))\r\n",
        "    \r\n",
        "class Discriminator(nn.Module):\r\n",
        "    def __init__(self, d_input_dim):\r\n",
        "        super(Discriminator, self).__init__()\r\n",
        "        self.fc1 = nn.Linear(d_input_dim, 512)\r\n",
        "        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features//2)\r\n",
        "        self.fc4 = nn.Linear(self.fc2.out_features, 1)\r\n",
        "    \r\n",
        "    # forward method\r\n",
        "    def forward(self, x):\r\n",
        "        x = F.leaky_relu(self.fc1(x), 0.2)\r\n",
        "        x = F.dropout(x, 0.3)\r\n",
        "        x = F.leaky_relu(self.fc2(x), 0.2)\r\n",
        "        x = F.dropout(x, 0.3)\r\n",
        "        return torch.sigmoid(self.fc4(x))\r\n",
        "\r\n",
        "# build network\r\n",
        "z_dim =128\r\n",
        "mnist_dim = train_dataset.train_data.size(1) * train_dataset.train_data.size(2)\r\n",
        "\r\n",
        "G = Generator(g_input_dim = z_dim, g_output_dim = 784).to(device)\r\n",
        "D = Discriminator(784).to(device)\r\n",
        "\r\n",
        "# loss\r\n",
        "criterion = nn.BCELoss() \r\n",
        "\r\n",
        "# optimizer\r\n",
        "lr = 0.0002 \r\n",
        "G_optimizer = optim.Adam(G.parameters(), lr = lr)\r\n",
        "D_optimizer = optim.Adam(D.parameters(), lr = lr)\r\n",
        "\r\n",
        "def D_train(x):\r\n",
        "    #=======================Train the discriminator=======================#\r\n",
        "    D.zero_grad()\r\n",
        "\r\n",
        "    # train discriminator on real\r\n",
        "    x_real, y_real = x.view(-1, mnist_dim), torch.ones(bs, 1)\r\n",
        "    x_real, y_real = Variable(x_real.to(device)), Variable(y_real.to(device))\r\n",
        "\r\n",
        "    D_output = D(x_real)\r\n",
        "    D_real_loss = criterion(D_output, y_real)\r\n",
        "    D_real_score = D_output\r\n",
        "\r\n",
        "    # train discriminator on facke\r\n",
        "    z = Variable(torch.randn(bs, z_dim).to(device))\r\n",
        "    x_fake, y_fake = G(z), Variable(torch.zeros(bs, 1).to(device))\r\n",
        "\r\n",
        "    D_output = D(x_fake)\r\n",
        "    D_fake_loss = criterion(D_output, y_fake)\r\n",
        "    D_fake_score = D_output\r\n",
        "\r\n",
        "    # gradient backprop & optimize ONLY D's parameters\r\n",
        "    D_loss = D_real_loss + D_fake_loss\r\n",
        "    D_loss.backward()\r\n",
        "    D_optimizer.step()\r\n",
        "        \r\n",
        "    return  D_loss.data.item()\r\n",
        "\r\n",
        "def G_train(x):\r\n",
        "    #=======================Train the generator=======================#\r\n",
        "    G.zero_grad()\r\n",
        "\r\n",
        "    z = Variable(torch.randn(bs, z_dim).to(device))\r\n",
        "    y = Variable(torch.ones(bs, 1).to(device))\r\n",
        "\r\n",
        "    G_output = G(z)\r\n",
        "    D_output = D(G_output)\r\n",
        "    G_loss = criterion(D_output, y)\r\n",
        "\r\n",
        "    # gradient backprop & optimize ONLY G's parameters\r\n",
        "    G_loss.backward()\r\n",
        "    G_optimizer.step()\r\n",
        "        \r\n",
        "    return G_loss.data.item()\r\n",
        "\r\n",
        "n_epoch = 100\r\n",
        "losses = []\r\n",
        "for epoch in range(1, n_epoch+1):    \r\n",
        "    D_losses, G_losses = [], []\r\n",
        "    for batch_idx, (x, _) in enumerate(train_loader):\r\n",
        "        D_losses.append(D_train(x))\r\n",
        "        G_losses.append(G_train(x))\r\n",
        "\r\n",
        "    print('[%d/%d]: loss_d: %.3f, loss_g: %.3f' % (\r\n",
        "            (epoch), n_epoch, torch.mean(torch.FloatTensor(D_losses)), torch.mean(torch.FloatTensor(G_losses))))\r\n",
        "    losses.append((torch.mean(torch.FloatTensor(D_losses)), torch.mean(torch.FloatTensor(G_losses))))\r\n",
        "\r\n",
        "fig, ax = plt.subplots()\r\n",
        "losses = np.array(losses)\r\n",
        "plt.plot(losses.T[0], label='Discriminator')\r\n",
        "plt.plot(losses.T[1], label='Generator')\r\n",
        "plt.title(\"Training Losses\")\r\n",
        "plt.legend()\r\n",
        "\r\n",
        "with torch.no_grad():\r\n",
        "    test_z = Variable(torch.randn(bs, z_dim).to(device))\r\n",
        "    generated = G(test_z)\r\n",
        "\r\n",
        "    save_image(generated.view(generated.size(0), 1, 28, 28), 'sample_' + '.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xQJCL9t9GPv"
      },
      "source": [
        "# prerequisites\r\n",
        "\r\n",
        "#VAE\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch.optim as optim\r\n",
        "from torchvision import datasets, transforms\r\n",
        "from torch.autograd import Variable\r\n",
        "from torchvision.utils import save_image\r\n",
        "\r\n",
        "bs = 100\r\n",
        "# MNIST Dataset\r\n",
        "train_dataset = datasets.MNIST(root='./mnist_data/', train=True, transform=transforms.ToTensor(), download=True)\r\n",
        "test_dataset = datasets.MNIST(root='./mnist_data/', train=False, transform=transforms.ToTensor(), download=False)\r\n",
        "\r\n",
        "# Data Loader (Input Pipeline)\r\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=bs, shuffle=True)\r\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=bs, shuffle=False)\r\n",
        "\r\n",
        "class VAE(nn.Module):\r\n",
        "    def __init__(self, x_dim, h_dim2, z_dim):\r\n",
        "        super(VAE, self).__init__()\r\n",
        "        \r\n",
        "        # encoder part\r\n",
        "        # self.fc1 = nn.Linear(x_dim, h_dim1)\r\n",
        "        self.fc2 = nn.Linear(x_dim, h_dim2)\r\n",
        "        self.fc31 = nn.Linear(h_dim2, z_dim)\r\n",
        "        self.fc32 = nn.Linear(h_dim2, z_dim)\r\n",
        "        # decoder part\r\n",
        "        self.fc4 = nn.Linear(z_dim, h_dim2)\r\n",
        "        self.fc5 = nn.Linear(h_dim2, x_dim)\r\n",
        "        # self.fc6 = nn.Linear(h_dim1, x_dim)\r\n",
        "        \r\n",
        "    def encoder(self, x):\r\n",
        "        # h = F.relu(self.fc1(x))\r\n",
        "        h = F.relu(self.fc2(x))\r\n",
        "        return self.fc31(h), self.fc32(h) # mu, log_var\r\n",
        "    \r\n",
        "    def sampling(self, mu, log_var):\r\n",
        "        std = torch.exp(0.5*log_var)\r\n",
        "        eps = torch.randn_like(std)\r\n",
        "        return eps.mul(std).add_(mu) # return z sample\r\n",
        "        \r\n",
        "    def decoder(self, z):\r\n",
        "        h = F.relu(self.fc4(z))\r\n",
        "        # h = F.relu(self.fc5(h))\r\n",
        "        return F.sigmoid(self.fc5(h)) \r\n",
        "    \r\n",
        "    def forward(self, x):\r\n",
        "        mu, log_var = self.encoder(x.view(-1, 784))\r\n",
        "        z = self.sampling(mu, log_var)\r\n",
        "        return self.decoder(z), mu, log_var\r\n",
        "\r\n",
        "# build model\r\n",
        "vae = VAE(x_dim=784, h_dim2=256, z_dim=2)\r\n",
        "if torch.cuda.is_available():\r\n",
        "    vae.cuda()\r\n",
        "\r\n",
        "vae\r\n",
        "\r\n",
        "optimizer = optim.Adam(vae.parameters())\r\n",
        "# return reconstruction error + KL divergence losses\r\n",
        "def loss_function(recon_x, x, mu, log_var):\r\n",
        "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\r\n",
        "    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\r\n",
        "    return BCE + KLD\r\n",
        "\r\n",
        "def train(epoch):\r\n",
        "    vae.train()\r\n",
        "    train_loss = 0\r\n",
        "    for batch_idx, (data, _) in enumerate(train_loader):\r\n",
        "        data = data.cuda()\r\n",
        "        optimizer.zero_grad()\r\n",
        "        \r\n",
        "        recon_batch, mu, log_var = vae(data)\r\n",
        "        loss = loss_function(recon_batch, data, mu, log_var)\r\n",
        "        \r\n",
        "        loss.backward()\r\n",
        "        train_loss += loss.item()\r\n",
        "        optimizer.step()\r\n",
        "        \r\n",
        "        if batch_idx % 100 == 0:\r\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\r\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\r\n",
        "                100. * batch_idx / len(train_loader), loss.item() / len(data)))\r\n",
        "    print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss / len(train_loader.dataset)))\r\n",
        "def test():\r\n",
        "    vae.eval()\r\n",
        "    test_loss= 0\r\n",
        "    with torch.no_grad():\r\n",
        "        for data, _ in test_loader:\r\n",
        "            data = data.cuda()\r\n",
        "            recon, mu, log_var = vae(data)\r\n",
        "            \r\n",
        "            # sum up batch loss\r\n",
        "            test_loss += loss_function(recon, data, mu, log_var).item()\r\n",
        "        \r\n",
        "    test_loss /= len(test_loader.dataset)\r\n",
        "    print('====> Test set loss: {:.4f}'.format(test_loss))\r\n",
        "    return test_loss\r\n",
        "    \r\n",
        "test_Loss_Contain = []\r\n",
        "for epoch in range(1, 51):\r\n",
        "    train(epoch)\r\n",
        "    x = test()\r\n",
        "    test_Loss_Contain.append(x)\r\n",
        "\r\n",
        "with torch.no_grad():\r\n",
        "    z = torch.randn(64, 2).cuda()\r\n",
        "    sample = vae.decoder(z).cuda()\r\n",
        "    \r\n",
        "    save_image(sample.view(64, 1, 28, 28), './sample_' + '.png')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}